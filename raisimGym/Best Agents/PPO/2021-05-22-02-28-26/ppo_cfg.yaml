seed: 1
record_video: yes

environment:
  simulation_dt: 0.0025
  control_dt: 0.01
  max_time: 15.0
  render: True

  num_envs: 240
  vis_every_n: 50
  visualize_eval: True
  num_threads: 40

  reward:
    position:
      coeff: -0.003
    relPosition:
      coeff: 0.00
    thrust:
      coeff: 0.000 # maybe not a good choice
    orientation:
      coeff: -0.002
    angularVelocity:
      coeff: -0.0005 # maybe not a good choice


architecture:
  shared_nets: False
  base_net: [64]
  policy_net: [64, 64]
  value_net: [64, 64]
  activation_fn: nn.Tanh
  deterministic_policy: False

helper:
  normalize_ob: True # (obs - obs_rms.mean) / obs_rms.var
  update_mean: False # update mean and var ob obs_rms
  scale_action: False # because scaling is done in Environment.hpp for better performance
  clip_action: False # either scale or clip action to [-1, 1]. Also works fine.

hyperparam:
  num_mini_batches: 3
  num_learning_epochs: 6
  shuffle: False
  Gamma: 0.998
  Lambda: 0.95
  clip_param: 0.2
  learning_rate: 0.00075
  value_loss_coef: 0.5
  use_clipped_value_loss: True # if True: PPO2, False: PPO
  entropy_coef: 0.0001

