seed: 1
record_video: yes

environment:
  simulation_dt: 0.0005
  control_dt: 0.01
  max_time: 11.0
  render: True

  num_envs: 80
  eval_every_n: 20
  num_threads: 20

  reward:
    position:
      coeff: 0.002
    thrust:
      coeff: 0.0001
    orientation:
      coeff: -0.002
    angularVelocity:
      coeff: -0.0001


architecture:
  policy_net: [64, 64]
  value_net: [64, 64]
  activation_fn: nn.LeakyReLU
  deterministic_policy: False # True: does not converge because action_loss will be used then
  normalize_ob: True
  clip_action: False # either scale or clip action to [-1, 1]


hyperparam:
  num_mini_batches: 4
  num_learning_epochs: 6
  shuffle: True
  Gamma: 0.99
  Beta: 0.8
  beta_scheduler: 0.0005
  learning_rate: 0.0005
  l2_reg_weight: 0.0
  entropy_weight: 0.0
  log_prob_loss: True

